
# Assignment 2 - Randomized Optimization

The code for this assignment runs a neural network experiment consisting of fairly large parameter searches and sensitivity analysis. It also runs four optimization algorithms against the Knapsack problem, the Continuous Peaks problem, and the flip-flop problem. 

## Setup
This repository uses a fork of the mlrose python package as a submodule in order to facilitate running experiments.

This submodule must first be configured by running `git submodule init` and `git submodule update` if the repository was not checked out recursively. 

You should then `cd` into the `third-party/mlrose` directory and run `pip install -e .` to install this local copy (as an editable package, which isn't strictly required, but was used for development.)

## Data

Datasets must be stored in the .data folder. A symlink is used, and this may not work on not Unix systems.

## Output
 
Output products are generally placed in the output/ directory, and are nested further for specific problems and algorithms.

## Running Experiments

To run all of the experiments in sequence, run `python run_all_experiments`. All output products will be generated by this script.

Individual experiments can be re-run by running:

`python flipflop.py`
`python knapsack.py`
`python cpeaks.py`
`python neuralnet.py`.

Plots can be regenerated for their respective components of the experiments by running:
`python plot_nn_results.py`
`python plot_toy_results.py`
